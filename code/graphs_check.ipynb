{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check created networks and plot example network\n",
    "\n",
    "After generating networks, it is important to check that they have the properties we expect. This notebook will read in a set of graph models and plot properties such as edge weight distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "\n",
    "using Statistics\n",
    "using Pkg\n",
    "using LinearAlgebra\n",
    "using StatsBase\n",
    "using Random\n",
    "using JLD\n",
    "using Plots\n",
    "using Distributions\n",
    "using JSON\n",
    "using MAT\n",
    "Pkg.add(\"ColorSchemes\")\n",
    "using ColorSchemes\n",
    "Pkg.add(\"PyCall\")\n",
    "using PyCall\n",
    "nx = pyimport(\"networkx\")\n",
    "np = pyimport(\"numpy\")\n",
    "\n",
    "include(\"helper_functions.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters\n",
    "\n",
    "The following will extract parameters from the designated configuration file. After running this block, you should see a list of graph files found that will be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from config file\n",
    "config_file = \"config101220.json\"\n",
    "config = read_config(\"$(homedir())/configs/$(config_file)\")\n",
    "\n",
    "const NNODES = config[\"NNODES\"]\n",
    "const MAXDIM = config[\"MAXDIM\"]\n",
    "const NREPS = config[\"NREPS\"]\n",
    "const DATE_STRING = config[\"DATE_STRING\"]\n",
    "const SAVETAIL = config[\"SAVETAIL_graphInfo\"]\n",
    "const read_dir = \"$(homedir())/$(config[\"read_dir_graphs\"])/$(NNODES)nodes\"\n",
    "\n",
    "\n",
    "# Locate and print graph files\n",
    "graph_files = filter(x->occursin(DATE_STRING,x), readdir(read_dir))\n",
    "\n",
    "println(\"Located the following graph files:\")\n",
    "for graph_file in graph_files\n",
    "    println(graph_file)\n",
    "end\n",
    "\n",
    "# Extract just the model names\n",
    "model_names = [split(graph_file,\"_\")[1] for graph_file in graph_files]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate plots\n",
    "\n",
    "The following will create one .pdf for each network model (each graph file found). The .pdf file by default will contain:\n",
    "\n",
    "- Heatmap of last network adjacency matrix\n",
    "- Strength distribution of the last network\n",
    "- Edge weight distribution of the last network\n",
    "- Averaged adjacency matrix over replicates\n",
    "- Distribution of node strength using all replicates\n",
    "- Distribution of edge weights using all replicates\n",
    "- Distribution of the average clustering coefficient\n",
    "- Distribution of modularity\n",
    "\n",
    "***Note*** The modularity calculations can take a significant amount of time. Consider commenting out these plots and calculations if they are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set styles for all plots. Though the resulting plots have funky colors/fonts, this makes it easier to \n",
    "# edit later in illustrator.\n",
    "default(titlefont = (20, \"times\"), legendfontsize = 18, guidefont = (18, \"times\", :darkgreen), tickfont = (12, :orange, \"times\"), guide = \"x\", framestyle = :zerolines, yminorgrid = true)\n",
    "\n",
    "# Loop over graph files and create a .pdf for each.\n",
    "for graph_file in graph_files\n",
    "    \n",
    "    # Extract weighted graph array\n",
    "    graph_dict = load(\"$(read_dir)/$(graph_file)\")\n",
    "    weighted_graph_array = graph_dict[\"weighted_graph_array\"]\n",
    "    nReps = size(weighted_graph_array)[3]\n",
    "\n",
    "    # Find last graph and calculate average graph\n",
    "    G_end = weighted_graph_array[:,:,nReps]\n",
    "    G_avg = dropdims(mean(weighted_graph_array, dims=3), dims=3)\n",
    "\n",
    "    # Heatmap of last graph\n",
    "    p1a = heatmap(G_end,yflip = true, aspect_ratio=:equal, grid = false, c = :gist_yarg, axis=false, xlims=[1,70],\n",
    "        framestyle=:box)\n",
    "    title!(\"Last graph\")\n",
    "    ylabel!(\"Nodes\")\n",
    "    xlabel!(\"Nodes\")\n",
    "    \n",
    "    # Strength distributions - last graph\n",
    "    p1b = histogram([sum(G_end, dims=1)...], legend = false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Strength distribution last graph\")\n",
    "    ylabel!(\"Frequency\")\n",
    "    xlabel!(\"Node strength\")\n",
    "\n",
    "\n",
    "    # Edge weight distributions - last graph\n",
    "    p1c = histogram(triu_elements(G_end,1), legend = false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Last graph edge weight distribution\")\n",
    "    ylabel!(\"Frequency\")\n",
    "    xlabel!(\"Edge weight\")\n",
    "    \n",
    "    # Heatmap - average graph\n",
    "    p1d = heatmap(G_avg,yflip = true, aspect_ratio=:equal, grid=false, c = :gist_yarg, xlims=[1,70], framestyle=:box)\n",
    "    title!(\"Average graph\")\n",
    "    ylabel!(\"Nodes\")\n",
    "    xlabel!(\"Nodes\")\n",
    "    \n",
    "    # Strength distribution - average graph\n",
    "    p1e = histogram([sum(weighted_graph_array, dims=1)...], legend = false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Strength distribution all graphs\")\n",
    "    ylabel!(\"Frequency\")\n",
    "    xlabel!(\"Node strength\")\n",
    "\n",
    "    # Edge weight distribution - average graph\n",
    "    p1f = histogram([weighted_graph_array...], legend = false, c=:gray, alpha = 0.3)\n",
    "    title!(\"All graphs edge weight distribution\")\n",
    "    ylabel!(\"Frequency\")\n",
    "    xlabel!(\"Edge weight\")\n",
    "\n",
    "\n",
    "    # Graph metrics\n",
    "    clustering = zeros(1,nReps)\n",
    "    modularity = zeros(1,nReps)\n",
    "\n",
    "\n",
    "    for rep in 1:nReps\n",
    "\n",
    "        g = nx.from_numpy_matrix(weighted_graph_array[:,:,rep], parallel_edges=false)\n",
    "        clustering[1, rep] = nx.average_clustering(g, weight = \"weight\")\n",
    "        modularity[1, rep] = nx.algorithms.community.modularity(g, nx.algorithms.community.label_propagation_communities(g))\n",
    "\n",
    "    end\n",
    "\n",
    "    # Clustering distribution \n",
    "    p1g = histogram([clustering...], legend=false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Average clustering (all graphs)\")\n",
    "    xlabel!(\"Avg. clustering\")\n",
    "    ylabel!(\"Frequency\")\n",
    "\n",
    "    # Modularity distribution\n",
    "    p1h = histogram([modularity...], legend=false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Modularity (all graphs)\")\n",
    "    xlabel!(\"Modularity\")\n",
    "    ylabel!(\"Frequency\")\n",
    "\n",
    "\n",
    "    # Add all subplots to main plot and write to pdf\n",
    "    pi1 = plot(p1a, p1b, p1c, p1d, p1e, p1f, p1g, p1h, layout = (8, 1), size=(400,2000))\n",
    "    savefig(\"../figures/$(replace(graph_file, \"_graphs.jld\" => \"\"))_$(SAVETAIL).pdf\")\n",
    "\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
