{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `/opt/julia/registries/General`\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Some registries failed to update:\n",
      "│     — `/opt/julia/registries/General` — registry dirty\n",
      "└ @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.2/Pkg/src/Types.jl:1171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.2/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `/opt/julia/environments/v1.2/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "compute_probability (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import packages\n",
    "\n",
    "using Statistics\n",
    "using Pkg\n",
    "using LinearAlgebra\n",
    "using StatsBase\n",
    "using Random\n",
    "using JLD\n",
    "using Plots\n",
    "using Distributions\n",
    "using JSON\n",
    "using MAT\n",
    "Pkg.add(\"ColorSchemes\")\n",
    "using ColorSchemes\n",
    "Pkg.add(\"PyCall\")\n",
    "using PyCall\n",
    "nx = pyimport(\"networkx\")\n",
    "np = pyimport(\"numpy\")\n",
    "\n",
    "include(\"helper_functions.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Located the following graph files:\n",
      "IID_70nodes_500reps_101220_graphs.jld\n",
      "assortative_70nodes_500reps_20_5_10_5_101220_graphs.jld\n",
      "clique10_70nodes_500reps_10_101220_graphs.jld\n",
      "clique15_70nodes_500reps_15_101220_graphs.jld\n",
      "clique20_70nodes_500reps_20_101220_graphs.jld\n",
      "clique25_70nodes_500reps_25_101220_graphs.jld\n",
      "clique2_70nodes_500reps_2_101220_graphs.jld\n",
      "clique30_70nodes_500reps_30_101220_graphs.jld\n",
      "clique35_70nodes_500reps_35_101220_graphs.jld\n",
      "clique5_70nodes_500reps_5_101220_graphs.jld\n",
      "clique_70nodes_500reps_101220_graphs.jld\n",
      "cliques10_70nodes_500reps_10_101220_graphs.jld\n",
      "cliques15_70nodes_500reps_15_101220_graphs.jld\n",
      "cliques20_70nodes_500reps_20_101220_graphs.jld\n",
      "cliques2_70nodes_500reps_2_101220_graphs.jld\n",
      "cliques35_70nodes_500reps_35_101220_graphs.jld\n",
      "cliques5_70nodes_500reps_5_101220_graphs.jld\n",
      "coreperiphery_70nodes_500reps_15_5_10_5_101220_graphs.jld\n",
      "cosineGeometric_70nodes_500reps_3_101220_graphs.jld\n",
      "disassortative_70nodes_500reps_20_5_10_5_101220_graphs.jld\n",
      "discreteUniformConf_70nodes_500reps_0_1000_101220_graphs.jld\n",
      "dotProduct_70nodes_500reps_3_101220_graphs.jld\n",
      "geometricConf_70nodes_500reps_001_100_101220_graphs.jld\n",
      "randomGeom_70nodes_500reps_3_101220_graphs.jld\n",
      "ringLattice_70nodes_500reps_101220_graphs.jld\n",
      "rmsd_70nodes_500reps_3_101220_graphs.jld\n",
      "sqdEuclidean_70nodes_500reps_3_101220_graphs.jld\n",
      "wprobTriangle0_70nodes_500reps_0_101220_graphs.jld\n",
      "wprobTriangle1_70nodes_500reps_01_101220_graphs.jld\n",
      "wprobTriangle2_70nodes_500reps_02_101220_graphs.jld\n",
      "wprobTriangle3_70nodes_500reps_03_101220_graphs.jld\n",
      "wprobTriangle4_70nodes_500reps_04_101220_graphs.jld\n",
      "wprobTriangle5_70nodes_500reps_05_101220_graphs.jld\n",
      "wprobTriangle6_70nodes_500reps_06_101220_graphs.jld\n",
      "wprobTriangle7_70nodes_500reps_07_101220_graphs.jld\n",
      "wprobTriangle8_70nodes_500reps_08_101220_graphs.jld\n",
      "wprobTriangle95_70nodes_500reps_095_101220_graphs.jld\n",
      "wprobTriangle9_70nodes_500reps_09_101220_graphs.jld\n",
      "wprobTriangle_70nodes_500reps_1_101220_graphs.jld\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"IID_70nodes_500reps_101220_graphs.jld\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "\n",
    "# Read from config file\n",
    "config_file = \"config101220.json\"\n",
    "config = read_config(\"$(homedir())/configs/$(config_file)\")\n",
    "\n",
    "const NNODES = config[\"NNODES\"]\n",
    "const MAXDIM = config[\"MAXDIM\"]\n",
    "const NREPS = config[\"NREPS\"]\n",
    "const DATE_STRING = config[\"DATE_STRING\"]\n",
    "const SAVETAIL = config[\"SAVETAIL_graphInfo\"]\n",
    "const read_dir = \"$(homedir())/$(config[\"read_dir_graphs\"])/$(NNODES)nodes\"\n",
    "const save_dir = \"$(homedir())/$(config[\"save_dir_forJason\"])/$(NNODES)nodes\"\n",
    "\n",
    "# Locate graph files\n",
    "graph_files = filter(x->occursin(DATE_STRING,x), readdir(read_dir))\n",
    "println(\"Located the following graph files:\")\n",
    "for graph_file in graph_files\n",
    "    println(graph_file)\n",
    "end\n",
    "model_names = [split(graph_file,\"_\")[1] for graph_file in graph_files]\n",
    "\n",
    "graph_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: pi1 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: pi1 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[3]:82"
     ]
    }
   ],
   "source": [
    "plot_array = Any[]\n",
    "\n",
    "default(titlefont = (20, \"times\"), legendfontsize = 18, guidefont = (18, \"times\", :darkgreen), tickfont = (12, :orange, \"times\"), guide = \"x\", framestyle = :zerolines, yminorgrid = true)\n",
    "\n",
    "for graph_file in graph_files\n",
    "# graph_file = \"IID_70nodes_200reps_092420_graphs.jld\"\n",
    "    \n",
    "    graph_dict = load(\"$(read_dir)/$(graph_file)\")\n",
    "    weighted_graph_array = graph_dict[\"weighted_graph_array\"]\n",
    "\n",
    "    nReps = size(weighted_graph_array)[3]\n",
    "    G_end = weighted_graph_array[:,:,nReps]\n",
    "    G_avg = dropdims(mean(weighted_graph_array, dims=3), dims=3)\n",
    "\n",
    "    p1a = heatmap(G_end,yflip = true, aspect_ratio=:equal, grid = false, c = :gist_yarg, axis=false, xlims=[1,70],\n",
    "        framestyle=:box)\n",
    "    title!(\"Last graph\")\n",
    "    ylabel!(\"Nodes\")\n",
    "    xlabel!(\"Nodes\")\n",
    "    \n",
    "    # Degree distributions\n",
    "    p1b = histogram([sum(G_end, dims=1)...], legend = false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Strength distribution last graph\")\n",
    "    ylabel!(\"Frequency\")\n",
    "    xlabel!(\"Node strength\")\n",
    "\n",
    "\n",
    "    # Edge weight distributions\n",
    "    p1c = histogram(triu_elements(G_end,1), legend = false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Last graph edge weight distribution\")\n",
    "    ylabel!(\"Frequency\")\n",
    "    xlabel!(\"Edge weight\")\n",
    "    \n",
    "    \n",
    "    p1d = heatmap(G_avg,yflip = true, aspect_ratio=:equal, grid=false, c = :gist_yarg, xlims=[1,70], framestyle=:box)\n",
    "    title!(\"Average graph\")\n",
    "    ylabel!(\"Nodes\")\n",
    "    xlabel!(\"Nodes\")\n",
    "    \n",
    "    p1e = histogram([sum(weighted_graph_array, dims=1)...], legend = false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Strength distribution all graphs\")\n",
    "    ylabel!(\"Frequency\")\n",
    "    xlabel!(\"Node strength\")\n",
    "\n",
    "    p1f = histogram([weighted_graph_array...], legend = false, c=:gray, alpha = 0.3)\n",
    "    title!(\"All graphs edge weight distribution\")\n",
    "    ylabel!(\"Frequency\")\n",
    "    xlabel!(\"Edge weight\")\n",
    "\n",
    "\n",
    "    # Graph metrics\n",
    "    clustering = zeros(1,nReps)\n",
    "    modularity = zeros(1,nReps)\n",
    "\n",
    "\n",
    "#     for rep in 1:nReps\n",
    "\n",
    "#         g = nx.from_numpy_matrix(weighted_graph_array[:,:,rep], parallel_edges=false)\n",
    "#         clustering[1, rep] = nx.average_clustering(g, weight = \"weight\")\n",
    "#         modularity[1, rep] = nx.algorithms.community.modularity(g, nx.algorithms.community.label_propagation_communities(g))\n",
    "\n",
    "#     end\n",
    "\n",
    "\n",
    "    p1g = histogram([weighted_graph_array...], legend=false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Average clustering (all graphs)\")\n",
    "    xlabel!(\"Avg. clustering\")\n",
    "    ylabel!(\"Frequency\")\n",
    "\n",
    "    p1h = histogram([weighted_graph_array...], legend=false, c=:gray, alpha = 0.3)\n",
    "    title!(\"Modularity (all graphs)\")\n",
    "    xlabel!(\"Modularity\")\n",
    "    ylabel!(\"Frequency\")\n",
    "\n",
    "\n",
    "#     pi1 = plot(p1a, p1b, p1c, layout = (3, 1))\n",
    "        pi1 = plot(p1a, p1b, p1c, p1d, p1e, p1f, p1g, p1h, layout = (8, 1), size=(400,2000))\n",
    "#         pi2 = plot(p1a,p1d, layout=(2,1))\n",
    "    savefig(\"../figures/$(replace(graph_file, \"_graphs.jld\" => \"\"))_$(SAVETAIL).pdf\")\n",
    "#     push!(plot_array,pi)\n",
    "end\n",
    "\n",
    "# plot(pi1)\n",
    "\n",
    "# plot(plot_array...,  size = (1700, 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting thresholded graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a big plot of graphs for each\n",
    "const read_dir_thresh = \"$(homedir())/$(config[\"read_dir_thresh\"])/$(NNODES)nodes\"\n",
    "\n",
    "# Maybe just betti bar first\n",
    "\n",
    "# Filter to just the thresholds\n",
    "\n",
    "thresh_files = filter(x->occursin(\"thresh\",x), readdir(read_dir_thresh))\n",
    "thresh_files = filter(x->occursin(\"$(DATE_STRING)\",x), thresh_files)\n",
    "thresh_files = filter(x->!occursin(\"noiseOnly\",x), thresh_files)\n",
    "\n",
    "# Locate the thresh nametages\n",
    "thresh_nametags = []\n",
    "for thresh_file in thresh_files\n",
    "    tag = split(split(thresh_file, \"graphs_\")[2], \"_edge\")[1]\n",
    "    thresh_nametags = [thresh_nametags; tag]\n",
    "end\n",
    "\n",
    "thresh_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through and make big graph\n",
    "\n",
    "for thresh_nametag in thresh_nametags\n",
    "    \n",
    "    thresh_files_filtered = filter(x->occursin(thresh_nametag,x), thresh_files)\n",
    "    \n",
    "    for thresh_file_filtered in thresh_files_filtered\n",
    "        \n",
    "        # read in graphs\n",
    "        graph_dict = load(\"$(read_dir)/$(thresh_file_filtered)\")\n",
    "        weighted_graph_array = graph_dict[\"weighted_graph_array\"]\n",
    "\n",
    "        nReps = size(weighted_graph_array)[3]\n",
    "        G_end = weighted_graph_array[:,:,nReps]\n",
    "        \n",
    "        # Convert to networkx graph\n",
    "        g = nx.from_numpy_matrix(G_end, parallel_edges=false)\n",
    "        nx.draw_networkx(g)\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Making giant star graph\n",
    "\n",
    "adj = zeros(20,20)\n",
    "nEdges = binomial(20,2)\n",
    "nNodes = 20\n",
    "\n",
    "for i=1:nNodes\n",
    "    for j = (i+1):nNodes\n",
    "        adj[i,j] = 1 ./abs(i-j)\n",
    "        adj[j,i] = 1 ./abs(i-j)\n",
    "        nEdges = nEdges-1\n",
    "    end\n",
    "end\n",
    "    \n",
    "heatmap(adj, yflip=true)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_interval = [0.5, 0.6]\n",
    "\n",
    "nNodes = 20\n",
    "nEdges = binomial(nNodes, 2)\n",
    "edge_weights = reverse!(collect(1:nEdges))\n",
    "edge_densities = [1-(j/nEdges) for j in edge_weights]\n",
    "\n",
    "function compute_probability(density, a, b)\n",
    "    \n",
    "    # Interval is [a, b]\n",
    "    # p(density) = 1/(b-a) * (density - a)\n",
    "    \n",
    "    m = 1 ./ (b-a)\n",
    "    \n",
    "    return m*(density - a)\n",
    "end\n",
    "\n",
    "adj1 = make_ring_lattice_wei(20)\n",
    "adj = makeEdgeWeightsUnique(adj1)\n",
    "random_probabilities = compute_probability.(edge_densities,0.3, 0.7)\n",
    "random_probabilities[random_probabilities .< 0] .= 0\n",
    "random_probabilities[random_probabilities .> 1] .=1\n",
    "# plot(edge_densities, random_probabilities)\n",
    "\n",
    "adj_overlap = zeros(nNodes,nNodes)\n",
    "\n",
    "\n",
    "a = 0.7\n",
    "b = 0.8\n",
    "\n",
    "edge_number = 1\n",
    "while edge_number <= nEdges\n",
    "    \n",
    "    density = edge_number/nEdges\n",
    "    \n",
    "    p = compute_probability(density, a, b)\n",
    "    \n",
    "    r = rand(1)[1]\n",
    "    \n",
    "    if r < p\n",
    "        \n",
    "        # Add edge at random\n",
    "        open_edges = Tuple.(findall(adj_overlap .== 0))\n",
    "        open_edges = filter(x -> (x[1] != x[2]), open_edges)\n",
    "        new_edge = sample(open_edges)\n",
    "        \n",
    "        adj_overlap[new_edge[1], new_edge[2]] = edge_number\n",
    "        adj_overlap[new_edge[2], new_edge[1]] = edge_number\n",
    "        \n",
    "        \n",
    "    else\n",
    "        \n",
    "        # Add edge from real graph. Take the maximum edge that could exist, because the random noise could\n",
    "        # have aded the intended edge already.\n",
    "        \n",
    "        identified_edge_weight = maximum([adj[adj_overlap.==0]...])\n",
    "#         println(identified_edge_weight)\n",
    "        \n",
    "        real_edges = findall(adj .== identified_edge_weight)[1]\n",
    "        \n",
    "       \n",
    "        \n",
    "        adj_overlap[real_edges[1], real_edges[2]] = edge_number\n",
    "        adj_overlap[real_edges[2], real_edges[1]] = edge_number\n",
    "        \n",
    "        \n",
    "        \n",
    "    end\n",
    "    \n",
    "    edge_number = edge_number+1\n",
    "end\n",
    "\n",
    "heatmap(adj_overlap)\n",
    "sort(unique([Int.(adj_overlap)...])) == collect(0:nEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique([Int.(adj_overlap)...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect(0:nEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binomial(70,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomize edge function\n",
    "include(\"graph_models.jl\")\n",
    "using Distances\n",
    "adj = make_random_geometric(20,3)\n",
    "adjt,t = threshold_graph(adj,0.5, 20)\n",
    "\n",
    "function randomize_edge_weights(adj)\n",
    "    \n",
    "    adj_rand = copy(adj)\n",
    "    adj_rand[adj_rand.>0] .=1\n",
    "    noiseyG = make_iid_weighted_graph(20)\n",
    "    adj_rand[adj_rand .==1] .= noiseyG[adj_rand.==1]\n",
    "    \n",
    "    return adj_rand\n",
    "end\n",
    "\n",
    "adjr = randomize_edge_weights(adjt)\n",
    "heatmap(adjr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(adjt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleteat!(collect(1:nNodes),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 800\n",
    "nNodes = 30\n",
    "\n",
    "# Define distribution\n",
    "d = DiscreteUniform(a,b)\n",
    "strength_sequence = rand(d,nNodes)\n",
    "\n",
    "adj = zeros(nNodes,nNodes)\n",
    "\n",
    "# Ensure sum of strength_sequence is even\n",
    "while sum(strength_sequence)%2 == 1\n",
    "    strength_sequence = rand(d,nNodes)\n",
    "\n",
    "end\n",
    "\n",
    "println(sum(strength_sequence))\n",
    "\n",
    "println(maximum(strength_sequence))\n",
    "\n",
    "# Create stubs array with stubs numbered by their parent node\n",
    "stubs_array = Array{Int64,1}(undef,(sum(strength_sequence)))\n",
    "for (node,strength) in enumerate(strength_sequence)\n",
    "  \n",
    "    \n",
    "#     println(v)\n",
    "    if node==1\n",
    "        stubs_array[1:strength_sequence[node]] .= node\n",
    "    else\n",
    "        u = cumsum(strength_sequence[1:(node-1)])[end]+1\n",
    "        v = cumsum(strength_sequence[1:node])[end]\n",
    "        println(u)\n",
    "        stubs_array[u:v] .= node\n",
    "    end\n",
    "\n",
    "    # stubs_array[] = [stubs_array; node.*ones(Int8, (strength))]\n",
    "end\n",
    "\n",
    "stubs_array2 = []\n",
    "for (node,strength) in enumerate(strength_sequence)\n",
    "    stubs_array2 = [stubs_array2; node.*ones(Int8, (strength))]\n",
    "end\n",
    "\n",
    "    \n",
    "# stubs_array = [node*ones(Int8, (strength)); for (node,strength) in enumerate(strength_sequence)]\n",
    "\n",
    "println(size(stubs_array2))\n",
    "println(size(stubs_array))\n",
    "\n",
    "isequal(stubs_array,stubs_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findfirst(stubs_array .!= Int.(stubs_array2))\n",
    "findfirst(stubs_array2 .!= 1)\n",
    "strength_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stubs_array2[350:367]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stubs_array[350:367]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
